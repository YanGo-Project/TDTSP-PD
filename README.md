# TDTSP-PD Solver

## Описание

Алгоритм для решения задач **оптимизации маршрута с динамической ценой перехода** (Time-Dependent Traveling Salesman Problem).

Реализация основана на статье:
> **"Applying Metaheuristics to the Time-Dependent Traveling Salesman Problem in Post-Disaster Situations"**  
> Ha-Bang Ban, 2021  
> [Ссылка на статью](https://www.atlantis-press.com/journals/ijcis/125954166/view)

---

## Формат данных

Входные и выходные данные имеют формат `*.json`. Структуры описаны в файле `include/problem_arguments.hpp`.

### Входные данные (InputData)

| Поле | Тип | Описание |
|------|-----|----------|
| `points_count` | `uint16_t` | Количество точек в задаче, включая склад (депо) |
| `min_load` | `uint16_t` | Минимальная загрузка исполнителя (мин. кол-во точек в маршруте) |
| `max_load` | `uint16_t` | Максимальная загрузка исполнителя (макс. кол-во точек в маршруте) |
| `max_time` | `int64_t` | Максимальное допустимое время маршрута |
| `max_distance` | `int64_t` | Максимальное допустимое расстояние маршрута |
| `distance_matrix` | `int64_t[N][N]` | Матрица расстояний между точками. Размерность: `points_count × points_count` |
| `time_matrix` | `int64_t[T][N][N]` | Матрица времени перемещения между точками. Размерность: `time_steps × points_count × points_count`. Склад имеет индекс 0. Разница между срезами — 30 минут |
| `point_scores` | `int64_t[N-1]` | Массив "важностей" (ценностей) всех точек, кроме склада |
| `point_service_times` | `int64_t[N-1]` | Массив времён на обслуживание каждой точки, кроме склада |

### Выходные данные (OutData)

| Поле | Тип | Описание |
|------|-----|----------|
| `route` | `uint16_t[]` | Последовательность индексов точек найденного маршрута |
| `solution_size` | `uint16_t` | Количество точек в решении |
| `total_time` | `int64_t` | ETA на прохождение маршрута (по `time_matrix` и `point_service_times`) |
| `total_distance` | `int64_t` | Суммарное расстояние маршрута (по `distance_matrix`) |
| `total_value` | `int64_t` | Суммарный скор (целевая функция) найденного маршрута |

---

## Установка зависимостей

В проекте используется библиотека [nlohmann/json](https://github.com/nlohmann/json).

**Linux:**
```bash
sudo apt install nlohmann-json3-dev
```
**macOS:**
```bash
brew install nlohmann-json
```

## 2. Сборка проекта 

Далее нужно выполнить следующие шаги:
1. ```mkdir build && cd build```
2. ```cmake -DCMAKE_BUILD_TYPE=Debug .. && cmake --build .```

Если все прошло успешно - в папке `build/` появится исполняемый файл **app**.

Для сборки в `Debug` моде вместо пункта 2 выполнить команду ```cmake -DCMAKE_BUILD_TYPE=Debug .. && cmake --build .```.

В данном формате:
1. В консоль будут выводиться промжеточные стадии улучшения маршрутов.
2. Будет происходить валидация маршрута после операции перестройки `crossover` (см. `include/crossover.hpp`).

## 3. Запуск скрипта и анализ результатов 

Для облегчения жизни и автоматизированного сбора и анализа результатов работы есть bash-скрипт.
Путь до него: `utils/run_experimetns.sh`.

### Структура и аргменты bash-скрипта 

Аргументы скрипта:

1. `$1` - путь до испольняемого файла, например `build/app`.
2. `$2` - путь до файла формата `.csv`, куда будут сохранены данные.
3. `$3` - количество запусков на один файл - нужно потому что в алгоритме много рандома.
4. `$4` - путь до папки где лежат входные данные, описанные в `FILES` (например `data/vrp_problems`).

Данные по запускам пишутся в csv файл в формате `problem_name, first_step_score, first_step_time, first_step_distance, second_step_score, second_step_time, second_step_distance`. 

Пример запуска: `./utils/run_experiments build/app result.csv 5 data/vrp_problems`. Так мы запустим сбор данных в result.csv с тестом каждого файла по 5 раз, это может занять до часа времени или даже больше, поэтому обращайте внимание на ход работы, который пишется в консоль.

### Анализ данных

Скрипт на питоне для работы с csv файлом - `utils/analyze_results.py`. Принимает на вход лишь один аргумент - путь до csv файла, названия колонок в нем захардкожены, поэтому меняйте аккуратно. Необходимые библиотеки лежат в `utils/requirements.txt`.

Пример запуска: `python3 utils/analyze_results.py results.csv`.

Что происходит внутри:
1. Выводит табличку "Avg значения по файлам" в консоль, где мы усреднили полученные значения для каждого из входных файлов.
2. Выводит табличку "Абсолютное улучшение после второго шага" в консоль, где мы для каждой из метрик пути (score, time, distance) выводим на сколько мы ее улучшили во втором шаге относительно первого.
3. Выводит табличку "Процентное улучшение после второго шага" в консоль, где мы для каждой из метрик пути (score, time, distance) выводим процентное улучшение, которое мы получили во втором шаге относительно первого.
4. Выводит среднее улучшение по каждой из метрик пути на всех входных данных.
5. Рисует графики целевой функции, времени, дистанции для первого и второго шагов работы алгоритма. Столбчатую диаграмму для абсолютного улучшения целевой фукнции, полученного во втором шаге. Файл: `experiment_results.png`.
5. Рисует столбчатые диаграммы для процентного улучшения целевой функции, времени и дистанции, полученного во втором шаге относительно первого. Файл: `experiment_results_improvements.png`.

## 4. Аргументы программы 
Необходимо выполнить следующее: 
```./app -p <problem> -s <solution> -t <time>```
Где:
1. @problem - файл с разрешением `.json`, в котором данные параметры системы.
2. @solution - файл с разерешнием `.json`, в который после работы алгоритма будет записано решение.
3. @time - время работы второй части алгоритма в секундах.

Пример:
```./app -p ../data/vrp_problems/1.json -s ../tests/vrp_temp/1.json -t 10```

## 5. Алгоритм 

Алгоритм делится на две логические части.

### Первая часть работы алгоритма 

Первая часть алгоритма полностью реализована в файле `src/first_step.cpp` и `include/first_step.hpp`.

Общая идея - пытаемся из всего множества вершин с помошью динамического программирования построить маршурт, 
который бы проходил входные ограничение по времени, расстоянию, минимальному и максимальному числу вершин в нем. 

### Вторая часть алгоритма 

На базе набора вершин из первого шага мы пытаемся перестроить маршурт, чтобы максимизировать целевую функцию 
и все еще вписываться во входные ограничения (время и расстояние пути).
Все идеи описаны в статье, которая лежит в `data/ban2021.pdf`. 
Файлы в `include/` являются различным частями алгоритма из статьи, которые затем собираются в метаэврестический алгоритм в файле `src/algorithm.cpp`.

#### Гиперпараметры второй части алгоритма 

Соответсвтующая им структура `MetaParameters` описана в `include/algorithm.hpp` и инициализируется в `main.cpp:40-49`.

Краткое описание: 
1. `population_size` - размер популяции, с которой мы работаем.
2. `alpha` - используется в генерации пути для популяции, отвечает за количество ближайших соседей к текущей последней вершине, среди которых случайно выбирается следующая.
3. `beta` - отвечает за распределение случайных и grasp путей в популяции, должен быть в [0, 1.0], если случайная величина принимает значение меньше, то генерируется случайный путь, иначе генерируется grasp путь.
4. `nloop` - количество итераций перестройки маршрута и его улучшения в VNS.
5. `kMax` - максимальное количество локальный улучшений, применяемых в VND.
6. `p` - допустимое ухудшение пути при его перестройке с `DoubleBridge` для выхода из локального минимума.
7. `max_iter_without_solution` - максимальное число итерация основного цикла работы алгоритма для популяции, если лучшее решение не меняется. Служит критерием останова работы.
8. `max_crossover_candidates` - максимальное число случайных путей из популяции для выбора двух лучших из них для построения нового маршурта.