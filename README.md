# DemoProject

## 1. Библиотека (де)сереализации JSON формата 
В проекте используется поплуряное решение 'nlohmann': https://github.com/nlohmann/json

Для его установки надо  выполнить команду:
1. ```sudo apt install nlohmann-json3-dev``` на Linux
2. ```brew install nlohmann-json``` на MacOs

## 2. Сборка проекта 

Далее нужно выполнить следующие шаги:
1. ```mkdir build && cd build```
2. ```cmake -DCMAKE_BUILD_TYPE=Debug .. && cmake --build .```

Если все прошло успешно - в папке `build/` появится исполняемый файл **app**.

Для сборки в `Debug` моде вместо пункта 2 выполнить команду ```cmake -DCMAKE_BUILD_TYPE=Debug .. && cmake --build .```.

В данном формате:
1. В консоль будут выводиться промжеточные стадии улучшения маршрутов.
2. Будет происходить валидация маршрута после операции перестройки `crossover` (см. `include/crossover.hpp`).

## 3. Запуск скрипта и анализ результатов 

Для облегчения жизни и автоматизированного сбора и анализа результатов работы есть bash-скрипт.
Путь до него: `utils/run_experimetns.sh`.

### Структура и аргменты bash-скрипта 

Аргументы скрипта:

1. `$1` - путь до испольняемого файла, например `build/app`.
2. `$2` - путь до файла формата `.csv`, куда будут сохранены данные.
3. `$3` - количество запусков на один файл - нужно потому что в алгоритме много рандома.
4. `$4` - путь до папки где лежат входные данные, описанные в `FILES` (например `data/vrp_problems`).

Данные по запускам пишутся в csv файл в формате `problem_name, first_step_score, first_step_time, first_step_distance, second_step_score, second_step_time, second_step_distance`. 

Пример запуска: `./utils/run_experiments build/app result.csv 5 data/vrp_problems`. Так мы запустим сбор данных в result.csv с тестом каждого файла по 5 раз, это может занять до часа времени или даже больше, поэтому обращайте внимание на ход работы, который пишется в консоль.

### Анализ данных

Скрипт на питоне для работы с csv файлом - `utils/analyze_results.py`. Принимает на вход лишь один аргумент - путь до csv файла, названия колонок в нем захардкожены, поэтому меняйте аккуратно. Необходимые библиотеки лежат в `utils/requirements.txt`.

Пример запуска: `python3 utils/analyze_results.py results.csv`.

Что происходит внутри:
1. Выводит табличку "Avg значения по файлам" в консоль, где мы усреднили полученные значения для каждого из входных файлов.
2. Выводит табличку "Абсолютное улучшение после второго шага" в консоль, где мы для каждой из метрик пути (score, time, distance) выводим на сколько мы ее улучшили во втором шаге относительно первого.
3. Выводит табличку "Процентное улучшение после второго шага" в консоль, где мы для каждой из метрик пути (score, time, distance) выводим процентное улучшение, которое мы получили во втором шаге относительно первого.
4. Выводит среднее улучшение по каждой из метрик пути на всех входных данных.
5. Рисует графики целевой функции, времени, дистанции для первого и второго шагов работы алгоритма. Столбчатую диаграмму для абсолютного улучшения целевой фукнции, полученного во втором шаге. Файл: `experiment_results.png`.
5. Рисует столбчатые диаграммы для процентного улучшения целевой функции, времени и дистанции, полученного во втором шаге относительно первого. Файл: `experiment_results_improvements.png`.

## 4. Аргументы программы 
Необходимо выполнить следующее: 
```./app -p <problem> -s <solution> -t <time>```
Где:
1. @problem - файл с разрешением `.json`, в котором данные параметры системы.
2. @solution - файл с разерешнием `.json`, в который после работы алгоритма будет записано решение.
3. @time - время работы второй части алгоритма в секундах.

Пример:
```./app -p ../data/vrp_problems/1.json -s ../tests/vrp_temp/1.json -t 10```

## 5. Алгоритм 

Алгоритм делится на две логические части.

### Первая часть работы алгоритма 

Первая часть алгоритма полностью реализована в файле `src/first_step.cpp` и `include/first_step.hpp`.

Общая идея - пытаемся из всего множества вершин с помошью динамического программирования построить маршурт, 
который бы проходил входные ограничение по времени, расстоянию, минимальному и максимальному числу вершин в нем. 

### Вторая часть алгоритма 

На базе набора вершин из первого шага мы пытаемся перестроить маршурт, чтобы максимизировать целевую функцию 
и все еще вписываться во входные ограничения (время и расстояние пути).
Все идеи описаны в статье, которая лежит в `data/ban2021.pdf`. 
Файлы в `include/` являются различным частями алгоритма из статьи, которые затем собираются в метаэврестический алгоритм в файле `src/algorithm.cpp`.

#### Гиперпараметры второй части алгоритма 

Соответсвтующая им структура `MetaParameters` описана в `include/algorithm.hpp` и инициализируется в `main.cpp:40-49`.

Краткое описание: 
1. `population_size` - размер популяции, с которой мы работаем.
2. `alpha` - используется в генерации пути для популяции, отвечает за количество ближайших соседей к текущей последней вершине, среди которых случайно выбирается следующая. (см. `src/init_population.cpp:101-103`)
3. `beta` - отвечает за распределение случайных и grasp путей в популяции, должен быть в [0, 1.0], если случайная величина принимает значение меньше, то генерируется случаный путь, иначе генерируется grasp путь.
4. `nloop` - количество итераций перестройки маршрута и его улучшения в VNS (см. `src/vns.cpp:10-26`).
5. `kMax` - максимальное количество локальный улучшений, применяемых в VND (см. `src/vnd.cpp:249`).
6. `p` - допустимое ухудшение пути при его перестройке с `DoubleBridge` для выхода из локального минимума (cм. `src/vnd.cpp:288`).
7. `max_iter_without_solution` - максимальное число итерация основного цикла работы алгоритма для популяции, если лучшее решение не меняется. Служит критерием останова работы (см. `src/algorithm.cpp:38`).
8. `max_crossover_candidates` - максимальное число случайных путей из популяции для выбора двух лучших из них для построения нового маршурта (см. `src/algorithm.cpp:35`)

В ходе тестов выяснилось, что порой на некоторых данных не получается сгенерировать популяцию нужного нам размера и мы уходим почти в бесконечный цикл из-за ограничений на время и дистанцию маршрута во входных данных. По этой причине ввелось дополнтиельное ограничение на количество попыток сгенерировать маршрут и работать с тем, что есть, чтобы не тратить процессорное время просто так (см. `max_iterations` в `src/init_population.cpp:15`).

## 6. Возможные улучшения 

1. Пока не производилось глобальных экспериментов по настройке гиперпараметров, но на локальных тестах можно было увидеть рзаницу в целевой фукнции (хоть и не большую) и во времени работы алгоритма. Возможно выстаривать гибкую настройку параметров от входных данных (каким образом стоить изучить) или же обучить модельку на их предсказание. 

2. Сейчас после первой части алгоритма используется маппинг для индексов вершин, чтобы во второй части апирировать индексами из [0...n] (см. `is_mapped` в `utils/problem_argumetns.cpp`). Глобально данное отображение не нужно и его можно удалить, на начальных стадиях использовалось для более простой работы с путем во второй части. 

3. Изучить методы инициализации начальной популяции более приближенные к реальной задаче (или можно допускать их в популяцию, но отсекать на более поздних стадиях), чтобы большая часть не отсекалась по ограничениям из входных данных.

4. Техническая возможность ускорить код - скорее всего в коде есть ненужные копирования пути (вектора вершин), что не всегда может быть дешево, особенно в масштабе того количества итераций, которые делаются. Можно попробовать отпрофилировать работу кода, чтобы найти на что больше всего тратиться времени и понять насколько важен нам этот "trade off" (дает ли нам эта работа цпу какие-то улучшения целевой функции) и возможно даже удалить некоторые части алгоритма. 

5. Новые версии локальных улучшений маршрута (см. `include/vnd.hpp OptimizationType`). Есть много вариаций в статьях на смежные темы, которые бы можно было лекго интегрировать в текущий пайплайн работы и проверить работоспособность на тестовых данных.

## 7. Баги 

Они скорее всего тут есть. Проводилсь валидация работы и корректности разных частей второго шага работы алгоритма, но все возможно - если найдется что-то, что Вам кажется работает не так - создавайте pull request в данный репозиторий с небольшим описанием проблемы и изменениями (опционально) + призывайте в него меня **Iskander Sabirov**